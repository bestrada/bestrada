\documentclass[12pt]{report}  

\usepackage{fullpage}  
\usepackage{setspace}  
\usepackage{graphicx}  
\usepackage{multirow}  
\usepackage{longtable}  

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
% COMMANDS THAT I USE TO DEFINE CONSTANTS 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\newcommand{\thetitle}{Software and the Law}  
\newcommand{\theauthor}{\textsc{Bryan G. Estrada}}  
\newcommand{\committeechair}{\textsc{Clark S. Turner}}  
\newcommand{\committeeA}{\textsc{David Janzen}}  
\newcommand{\committeeB}{\textsc{\ldots}}  
\newcommand{\theuniversity}{California Polytechnic State University}  
\newcommand{\thecity}{San Luis Obispo}  
\newcommand{\thedegree}{Master of Science in Computer Science}  
\newcommand{\thedate}{November 2008}  

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  
% COMMANDS FOR FOOTNOTES  
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  

\newcommand{\footnoteremember}[2]{  
\footnote{#2}  
\newcounter{#1}  
\setcounter{#1}{\value{footnote}}  
}  
\newcommand{\footnoterecall}[1]{  
\footnotemark[\value{#1}]  
}  
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  
% this is an environment so we can make wide figures and tables  
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  
\newenvironment{narrow}[2]{  
\begin{list}{}{  
  \setlength{\topsep}{0pt}  
  \setlength{\leftmargin}{#1}  
  \setlength{\rightmargin}{#2}  
  \setlength{\listparindent}{\parindent}  
  \setlength{\itemindent}{\parindent}  
  \setlength{\parsep}{\parskip}}  
\item[]}{\end{list}}  

\begin{document}  

\title{\thetitle}  
\author{\theauthor}  

\doublespace  

\pagenumbering{roman}  

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  
% TITLE PAGE  
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  
\begin{titlepage}  
\thispagestyle{empty}  
\begin{center}  

\textsc{\LARGE \thetitle}\\[4cm]  

A Thesis\\  
Presented to\\  
the Faculty of \theuniversity\\  
\thecity\\[4cm]  

In Partial Fulfillment\\  
of the Requirements for the Degree\\  
\thedegree  

\vfill  
by\\  
\theauthor\\  
\thedate  
\end{center}  

\end{titlepage}  

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  
% COPYRIGHT AUTHORIZATION PAGE  
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  
\begin{center}  
\textsc{\large Authorization for Reproduction\\of Master's Thesis}\\[3cm]  
\end{center}  

\noindent I grant permission for the reproduction of this thesis in its entirety  
or any of its parts, without further authorization from me.\\[4cm]  

\singlespace  
\noindent\makebox[4in]{\hrulefill}\\  
Signature\\[2cm]  

\noindent\makebox[4in]{\hrulefill}\\  
Date  
\doublespace  
\newpage  

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  
% SIGNATURE PAGE  
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  
\begin{center}  
The thesis of \theauthor,\\  
``\textsc{\large \thetitle}'',\\  
is approved.\\[4cm]  
\end{center}  

\singlespace  
\noindent\makebox[4in]{\hrulefill}\\  
Professor \committeeA\\[2cm]  

\noindent\makebox[4in]{\hrulefill}\\  
Professor \committeeB\\[2cm]  

\noindent\makebox[4in]{\hrulefill}\\  
Professor \committeechair, Committee Chair\\[4cm]  

\doublespace  

\newpage  

\begin{center}\textsc{\large Abstract}\\[1cm]\end{center}  
\addcontentsline{toc}{chapter}{Abstract}  
Software has become an integral part of our society. People have found many uses for software, some of which can result in human injury or death if the software it relies on fails to function properly. This work recognizes these software applications as safety-critical and addresses them by specifying the legal regulations imposed on the engineers that design, develop, and test them. This work also reveals how software engineers can fulfill these requirements and subsequently influence the very laws that constrain their work. The interactions between the law and software process show how software engineers can deal with the legal implications that help ensure better, safer software.  
\newpage  

\begin{center}\textsc{\large Acknowledgements}\\[1cm]\end{center}  
\addcontentsline{toc}{chapter}{Acknowledgements}  
I would like to express the utmost gratitude to Professor Clark Turner. His enthusiasm has been inspiring and his insights invaluable. I owe much of my success, both academic and professional, to his genuine encouragement and positive influence.  


I would also like to thank my parents, Jim and Lourdes. Without your unwavering support and direction I would not be the person I have become. I hope you are proud.  

\tableofcontents
\listoffigures\addcontentsline{toc}{chapter}{List of Figures}  


\chapter{Introduction}  
\pagenumbering{arabic}  

Organizations today are in the business of producing better products faster, cheaper, and more efficiently. As a result of society's stringent demands, these organizations utilize software to solve their problems. Many believe that software can be deployed more quickly and efficiently than traditionally engineered physical components. Over the years, computers have progressed to the point where this is not only possible, but more economically and conceptually feasible than using solely hardware components. Software has become so accessible that previously impossible feats are now incredibly easy to achieve.  

While this faith in software is warranted, it does not come without risk. Despite benefit of cost and its advantages in flexibility and functionality, software allows for an unprecedented possibility of error \cite{Brooks87}. \textit{Safety-critical} systems are those systems whose failure may cause injury or death to human beings. Such systems have been using software in their implementations for some time \cite{Therac25}, and disputes have already occurred regarding their stability\footnote{While \cite{Therac25} did not enter litigation because it was settled out of court, the cases in the appendices have been reviewed by their respective state courts.}. Therefore, it is fair for society to expect software developers to take specific precautions when developing safety-critical applications. Many software engineers may not realize that the law generally requires that they be subject to liability from harm to persons or property caused by defects in their software \cite{FAKE}. 

\section{Research Questions}  

Because of its unique nature, defects in software are inevitable and typically more difficult to locate and handle than physical flaws in mechanical components \cite{Parnas90}. Defects in the safety-critical realm can be especially dangerous. Software applications in products like video games, spreadsheets, and web browsers are understandably not dangerous to humans. But microprocessors and software are already being used to control prosthetic limbs \cite{Graupe78}, to help restore sight to the blind \cite{Fox95}, to automate the braking systems in cars \cite{Hurtig94}, and even to treat cancer patients with radiation \cite{Therac25}.

Using a complex artifact like software in safety-critical systems creates a predicament that our legal system is not fully prepared to handle. Yet despite its shallow history in software-related adjudication, the legal system imposes constraints on software engineering activity. The law constrains manufacturers to a standard of care that must be met to avoid liability \cite{FAKE}. This thesis closely examines the software development process and adopts legal constraints as requirements to this process. Effective processes drive software development and, when executed properly, can prevent future harm during the product's use. This research posits and addresses these three general questions: \singlespace  
\begin{enumerate}  
\item What are the legal constraints that software engineers must abide by in building safety-critical software?  
\item How do software engineers integrate these constraints into their processes?  
\item Who or what determines the universal standard for software engineers to follow?  
\end{enumerate}\doublespace  

\section{Contributions to Scholarship}  

This research seeks to show software engineers that common law cases provide implicit constraints on the development activities they perform. Software development  creates a product just like any other manufacturing process and those involved in the engineering of the product are responsible for the safety of the its users. This work describes the social responsibilities that software engineers are held to and explains the intrinsic differences of software that perhaps obscure the notions of legal liability. 

Future chapters will show where in the software process these legal constraints should be considered and how best practices can be used fulfill these requirements. In fact, with the proper application of previously documented development practices, software engineers in the safety-critical realm may already be fulfilling their legal duties. 

Finally, this research will show that these legal constraints can only be applied in the context of the software engineering ``state-of-the-art'', a capacity developed by software engineers themselves. In this sense, software engineers have control over the very legal requirements that they are held to. 

\chapter{Motivation} 

The technical progress of modern society has improved greatly in recent years and will continue to improve as new innovations are made. The result of technical progress is products that we use to somehow improve our lives. The automobile and airplane solve our transportation problems. Telephones and the Internet solve our communication problems. Software solves complex problems found in machines and devices that would otherwise be impossible or impractical to implement. There are countless products that are the result of technical innovation which act as solutions to improve our lives. 

However, innovation is not strictly motivated by altruism. Businesses and organizations also build products to make money. The economic factors involved in the sale of products influence several key areas in the software development process: design methodologies; development resources; and testing coverage are only a few examples. Because of these conflicting forces (profit, utility, deadlines, safety\ldots), software defects \textit{will} occur in safety-critical applications. Fortunately, the industry tends to improve and learns from its mistakes. 

\section{Defect: an inevitable necessity} 
While it is effectively impossible to prevent \textit{every} defect in software, some scholars would assure consumers that, for the most part, the majority of engineered products (like software) functions safely, as they should and as they are designed to do \cite{Petroski85}. This is because engineers have made mistakes in the past and have learned from these mistakes. Some argue that not only are we certain to come across devastating engineering mistakes, but such mistakes are necessary for the sake of improving engineering \cite{Petroski85}. 

Author and professor Henry Petroski claims that without tragic mishaps of engineered products, the industry would not have learned how to prevent them or even consider such mistakes in the first place! He cites examples such as the 1981 collapse of the Kansas City Hyatt Regency Hotel skywalks, the 1944 Tacoma Narrows Bridge collapse, and the 1979 American Airlines DC10 crash in Chicago. Failures like these need to occur and they need to be grand and public so that engineers will pay attention to and correct them. Engineers who work on individual products learn lessons from the entire industry.

\begin{figure}[t]  
\begin{center}  
\includegraphics[scale=0.77]{figures/graph.pdf}  
\end{center}  
\caption{Defect Tracking Over Time}  
\label{fig:bugs}  
\end{figure}  

The graph in Figure \ref{fig:bugs} qualitatively models the discovery of defects over time of a single engineered product during its development lifecycle. The y-axis represents the percentage of defects found in the product. The x-axis represents time starting at the point where engineering begins. Logically, the percentage of defects found increases over time through various engineering best practices. Additionally, as defects are found and fixed, the rate at which they are discovered should theoretically decrease. As time progresses, the percentage of defects found approaches, though very likely never reaches, 100\%. The curve is a limit that approaches complete defect coverage. The point in time that the product is released to the public intersects with the defect curve leaving some amount of defects undiscovered. The percentage of undiscovered defects that remain in product \textit{after} it is released is subject to liability. By learning from the mistakes of the past and identifying the best practices that should take place before this point in time, engineers can increase the defects found and repaired before they release to market, thus minimizing the defects subject to liability. 

The term \textit{liability} is a legal one, but in general, it refers to the responsibility of engineers to produce safe products before they release them and their accountability if they fail to produce such safety. To understand the concept of liability more fully and in the context of this research, it helps to understand the types of defects software engineers can be liable for.

\section{On defect classification in software}
Engineers releasing safety-critical products would love to be able to guarantee 100\% safety, but unfortunately there is no tool to use or process to follow that would allow them to do so \cite{Brooks87}. The edge cases that can cause injury will happen and software engineers will learn from these mistakes. Such mistakes are legally classified as a \textit{product defect}. A product that is defective ``contains some imperfection that makes it legally inadequate'' \cite{Turner99}. This work is interested in laying out the processes that would at least minimize the risk of safety-critical software and reduce the harm that would result from those defects that are overlooked.

It is necessary to distinguish the type of legal defect a product is held against so that the courts can determine the standard of liability to be imposed--e.g. strict liability or negligence--and thus, the proof necessary to warrant a case. Product defects fall into three categories \cite{Rest3d}: (a) manufacturing defects; (b) design defects; and (c) warning defects. Warning defects are not necessarily part of the actual product and thus this research dismisses this third class of defect\footnote{Turner points out in \cite{Turner99} that the duty to warn may not even be applicable to software engineers \cite{Turner99}. If software engineers knew of the specific risks they would be required to warn users about, they should redesign the software to account for them in the first place!}. Manufacturing and design defects are explained more fully below \cite{Rest3d}. 
\begin{itemize} 
\item\textbf{Manufacturing Defect:} A manufacturing defect is a flaw in the product that, though all possible care is taken during its engineering, departs from the intended design. 
\item\textbf{Design Defects:} A design defect is an error in the actual design of the product. The design is defective when the foreseeable risks of harm could have been reduced or avoided by the adoption of a reasonable alternative design.
\end{itemize} 
Research has concluded that software code can easily contain both classes of defect and that the current, practical body of evidence available in software engineering (specifications, documentation, source code, etc.) is insufficient for determining the class of defect in arbitrary cases. Software engineers can be held liable for both types of defect, but the manufacture of software can in many ways be considered design\footnote{The intrinsic properties of software that would lead scholars to this conclusion are explained in Chapter \ref{software_process} and more fully in \cite{Turner99}.}. Hence, this research seeks to prepare software engineers by discussing the process that can improve defect prevention in design. In so doing, this thesis aims to refine the behavior of software engineers in the safety-critical realm to improve the overall safety of their products and avoid the risk of legal dispute. 

\section{Summary}
Society has entered an age of high technology where innovation becomes real and in record time. Businesses and organization capitalize on peoples' want for the faster, easier, and more convenient. But the economic interests of these organizations and the inevitability of human imperfection put people in harm's way.

Defects will manifest themselves in products that people use and lead to injury. The engineers who build these products are held liable for such defects. The law is a system that victims can use to enforce this liability. This research is motivated by the classification of these defects in a legal context and the possibility of preventing them.

\chapter{Legal Background}  

\begin{quote} 
``\textit{\ldots [the law], by the very necessity of its nature, is continually transmuting those moral standards into external or objective ones\ldots}'' 
\flushright{\textsc{-Oliver Wendell Holmes} \cite{Holmes23}} 
\end{quote} 

Whether software engineers are aware of it or not, the programs they write are heavily regulated by the law. In software as with many other industries, there is a struggle between safety, cost, and utility. This chapter examines how legal regulation for product safety affects technical design and ultimately the implementation of these products. 

\section{Legal Procedure}  

The broad intent of the law is to achieve and preserve justice. In order to assure the safety of products, the law will likely rely on common law principles during disputes. The \textit{common law} regulates based on precedence from judgments found in previous courtroom decisions rather than exclusively on statutes adopted by legislative bodies.  

In the context of safety-critical software engineering, in order for the legal system to be invoked, some sort of disputable accident causing injury must occur. Victims who have suffered loss file a claim. Facts are gathered by searching through evidence and recording testimonies. After all parties agree on the facts, a trial takes place and both sides make arguments calling into question the legality of what occurred using precedent set from previous judgments stored in legal archives. A judge interprets what the law states and either he or a jury decides how it will apply in each individual case. Once the judge renders a decision, cases like this oftentimes undergo an appeal wherein the unsatisfied party petitions a higher court to review the decisions of the lower court to correct potential errors. The parties make more arguments on the legality of the previous decision, but new facts, testimony, and evidence are not accepted. When an appellate decision is made, that holding enters legal archives and serves as precedent for future cases. This process is referred to as the common law.  

\begin{figure}[t]  
\begin{center}  
\includegraphics[scale=0.73]{figures/commonlaw.pdf}  
\end{center}  
\caption{Common Law Process}  
\label{fig:commonlaw}  
\end{figure}  

The model in Figure \ref{fig:commonlaw} is a simplification of how the common law system in the United States handles disputes, specifically disputes involving defective products, and updates itself through an iterative feedback process. Input data to the trial includes facts, testimony, and the legal archives which consist of rulings and opinions from previous disputes. These rulings can be used to make decisions in current and future cases and is how the common law updates itself. If an unprecedented situation comes to suit, then the courts interpret similar situations and apply at the discretion of the judge. When a decision is rendered here, it becomes a resource for future disputes. 

The particulars of the adjudication process are less important than the core of how the common law functions. What is noteworthy of the model in Figure \ref{fig:commonlaw} is the application of legal decisions to each scenario. Rather than creating statutes from theory, common law cases use actual incident to make decisions about disputes. This means that the litigators, witnesses, and the parties involved in the dispute are, in part, responsible for setting precedent for future cases. Incidentally, this means that the common law is a reactive system because only after accident or injury occurs will legal repercussions be dealt with. When a judgment is made, it can then be applied to future scenarios, but usually only if a lawsuit is filed first. This timeless nature of the common law means that while it is not as easy to interpret as hard statutes, it is, in essence, future proof. 

\section{Characteristics of the Common Law}  

The common law is ``that part of the law that is within the province of the courts themselves to establish'' \cite{FAKE}. It exhibits many characteristics that make it just. Social propositions (those of morality, policy, or experience rather than state legal rules) are enforced impartially to any party. The courts practice a replicable system of litigation, allowing future disputants to receive legal advice. The common law is also responsive to change as moral norms evolve over time \cite{FAKE}.  

Those who are affected by the common law should understand the basic principles of its underpinnings. Software engineers working on safety-critical projects are pressured by social expectations for reliable and functional software. But because of its unique nature, defects in software are inevitable and typically more difficult to locate and fix than the physical flaws found in mechanical components \cite{Parnas90}. Defects in software used in safety-critical situations can be especially dangerous. The increasing use of software in machines and the demand for more products functions adds additional complexity and room for error. 

Fortunately, the legal system can account for this inherent complexity. For disputes resulting in injury or death from defective software, the most appropriate claim a plaintiff can make against software engineers will be of tortious behavior of the defendant. A \textit{tort} is a civil (not criminal) wrong or breach of duty to another person. Courts chosen to resolve these types of disputes will tend towards regulation through products liability law \cite{FAKE}. Products liability is almost exclusively regulated by common law decisions, meaning that cases under it must be resolved by applying rules generated by prior decisions. In addition to being applicable to software related disputes, products liability law resolves some of the complexity found in safety-critical software because disputes are closely examined on a case-by-case basis and there are no strict universal statutes that would simplify a decision. 

\section{Products Liability}  
The term \textit{products liability} is the area in law that broadly applies to the liability of a manufacturer or seller for injury to a buyer caused by a product that they sold \cite{FAKE}. A \textit{product} usually refers to physical merchandise that can be purchased. Officially, a product is defined as  

\begin{quote} 
``\textit{\ldots tangible personal property distributed commercially for use or consumption and other items, such as real estate property and electricity, when the context of their distribution and use is sufficiently analogous to the distribution and use of tangible personal property\ldots} (\cite{Rest3d}, \S19(a))''  
\end{quote} 

In the case of safety-critical systems, software is usually embedded in some machine or hardware device \cite{Leveson95} that is sold as a product. When viewed from this standpoint, software is less analogous to pure thoughts and expressions and is considered a product for products liability cases. Regardless, this research assumes that software is considered a product. 

Within products liability, a tortious act can be classified as either strictly liable or negligent \cite{Turner99}. Strict liability applies to any product that is defective, regardless of the process used to manufacture. While strict liability is interesting, this research is concerned with the \textit{process} used to build software and how engineers employ it. Since process is behavioral, it falls under the jurisdiction of negligence. 

\subsection{Negligence} 

Negligence is more concerned with the process used to build a product, not the product itself. Because manufacturing or design based defects are difficult, in fact nearly impossible, to classify \cite{Turner99}, applying negligence to software related incidents is even more appropriate. In general, the legal term \textit{negligence} refers to careless conduct. Scholars describe negligence\footnote{\textit{See:} 57A Am. Jur. 2d Negligence \S 5} more specifically as:\singlespace 
\begin{itemize} 
\item the existence and violation of a legal duty to use care, proximately  
causing injury to another. 
\item the failure to exercise the degree of care demanded by the circumstances. 
\item the breach of a duty to another to protect him or her from the particular 
harm that ensued. 
\item the want of that care the law prescribes under the particular 
circumstances existing at the time of the act or omission which is involved. 
\end{itemize}\doublespace 
Negligence can be applied to many different scenarios beyond products liability. An intoxicated driver who disobeys traffic laws may be negligent towards other citizens of the road\footnote{\textit{See: People v. Townsend}, 214 Mich. 267, 272, 183 N.W. 177.}. A instructor who fails to demonstrate safety precautions to his students in wood shop may be liable for negligence\footnote{\textit{See: Voorhies v. Conroe Independent School Dist.}, 610 F.Supp. 868.}. An engineer who does not adequately inspect his safety-critical product can be negligent to his clients\footnote{\textit{See: Ford Motor Co. v. Mondragon}, 271 F.2d 342.}. This research focuses on the negligence constrains as they apply to products liability. 

Negligence is easiest to determine when some standard of care stated by the profession is available. Lawyers are held to a standard defined by their state's Bar Association and doctors are licensed by the state's medical board. But while there are standards and best practices defined for software engineers \cite{FAKE}, no similarly legal official standard exists for software engineering. A more qualitative approach must be taken. The duty of software engineers are expected to fulfill is that of one who is reasonably prudent. Reasonably prudent software engineers would use the best available technologies at a reasonable cost and follow what is, at the time of implementation, considered to be the industry ``state-of-the-art''. 

Figure \ref{fig:handtest} shows a formula that equates negligence in terms of unreasonable behavior.  According to the Learned Hand test\footnote{\textit{See: United States v. Carroll Towing Co.}, 159 F.2d 169.\\ Judge Learned Hand created this guideline to determine the amount of duty owed in a negligence dispute. In the case, the United States sought compensation for flour that was lost when a barge carrying the cargo sunk. The barge company was partly responsible because no workers were present on the barge when it sank, which may have prevented the barge from sinking. Qualitatively, the amount it would have cost to keep a worker on the barge would have been less than the product of the probability that the barge sank and the amount of damages incurred from it sinking.}, an organization that develops safety-critical software has a duty to spend at least the amount of time and resources equivalent to the product of the severity of harm and the likelihood that it will happen. If they do not, then their actions are negligent. The Learned Hand test is an important metric because it provides a way to evaluate the existence of negligence without the presence of a strict standard. 

\begin{figure} 
\begin{narrow}{-1.5in}{-1.5in}\begin{center} 
\begin{tabular}{|l|} 
\hline 
	Let \textbf{B} be the burden (expense) of preventing a potential accident.\\ 
	Let \textbf{L} be the severity of the loss if the accident occurs.\\ 
	Let \textbf{P} be the probability of the accident.\\[6pt] 
	Then \textit{failure to attempt to prevent a potential accident is  
	unreasonable if}\\[8pt] 

     \centerline{\(B < P \times L\)} 
\\[3pt] 
\hline 
\end{tabular} 
\end{center}\end{narrow} 
\caption{The Learned Hand Test for Negligence} 
\label{fig:handtest} 
\end{figure} 
\subsubsection{Elements of Negligence} 
The laws of negligence can only be invoked under certain conditions. The prerequisites, or prima facie elements, of a negligence case are that \cite{Dobbs01}: 
\singlespace 
\begin{enumerate} 
\item there exists a duty of care (or duty to protect) 
\item the defendant breaches this duty with unreasonably risky conduct 
\item the defendant's conduct resulted in harm to the plaintiff 
\item the negligent conduct was a proximate cause of harm 
\item legally recognized damages or injury exist 
\end{enumerate} 
\doublespace 
In the fictional scenario, \textit{The Case of the Killer
Robot}\footnote{\textit{The Case of the Killer Robot} is a fictional scenario created by Richard G. Epstein to illustrate the complexity of building real-world software and the ethical issues introduced in the safety-critical realm. It is referenced in \cite{Epstein96} and reprinted with academic permission in Appendix \ref{A:killerrobot}.}, employees of Silicon Techtronics Inc. wrote software for robotics that were to manufacture products at Cybernetics Inc. The software contained latent defects that ultimately lead to the death of Cibernetics employee Bart Matthews. This scenario poses an ideal case study for the legal issues surrounding software development and the applicability of negligence.

Negligence cases call for an actual duty of care owed to a plaintiff. There may be a question about how much care is owed in a given situation, but there are circumstances in which there is no duty owed that bears on the harm a plaintiff suffers. Judges decide whether or not this duty exists. In the killer robot example, Silicon Techtronics Inc. is held to a duty of care expected by users of their machinery. Since their software controls machines that are capable of injuring humans, it is reasonable for users to expect some amount of care to be taken to prevent this. 

Also, there must be a breach of this duty of care owed. A defendant who behaves reasonably and exercises the necessary care required by law will not be negligent even if the plaintiff is harmed. The facts in the killer robot case evidence that Silicon Techtronics breached this duty. Their development practices were questionable at best, but factors like utility and practicality should be brought into question. 

The defendant's negligence must be the cause of the harm suffered by the plaintiff. A careless engineer who does not test his product is not negligent to the user who is injured by tripping over the machine. In addition, the cost must not only be the cause in fact, but a proximate, or primary cause of the harm suffered. This requirement is difficult to apply in the killer robot case. While it can be argued that Silicon Techtronics' processes did not follow the software engineering state-of-the-art, it is difficult to prove that this allegedly negligent behavior actually lead to the mistakes that Randy Samuels made. 

Finally, actual damages or injures must be suffered for a negligence case to follow suit. This can include personal injury or damages to property. 

\subsubsection{Why hasn't our legal system addressed software negligence?}  

The American legal system has still yet to resolve a \textit{real} dispute involving software. As software has now been around for decades and has already caused problems worthy of litigation \cite{FAKE}, why haven't our courts regulated for safer software?  

One reason why our courts have not addressed the issue of software safety is because of out-of-court measures that companies will take to settle disputes. Oftentimes, disputes will be settled through mediation, wherein a neutral third party facilitates a compromise of the situation \cite{FAKE}. Unfortunately, the law does not get updated through mediation because this kind of dispute resolution does not make a determination of right or wrong, it merely creates an agreement not to pursue trial litigation. Authority that constrains trial court judges, and subsequently software engineers that face such trials, is only developed by appeals courts. Appellate review produces the legal requirements and constraints for real trials.  

Often, cases will be dismissed in real trials because of out-of-court settlements wherein the defendant compensates the plaintiff at an amount agreed upon by both parties. 

\section{Addressing Cost} 

While the legal system (among other things) ensures the safety of products, the law understands the costs involved in ensuring safety measures and takes this into account when resolving disputes. Scholars posit that the law balances these economic forces and ensures safety to a reasonable cost to manufacturers \cite{FAKE}. 

Some lawyers contend that the law evolves towards efficient decisions in accident disputes in courts, where ``\textit{efficient}'' in this context means the defendant-manufacturer is more likely than the plaintiff-victim to win the suit if an accident occurs. In terms of software engineering, this means that an organization that develops safety-critical software will, in the long run, tend towards winning or possibly avoiding dispute. This is a good thing because it means the quality and safety of software improves. In fact, software quality and safety must improve if the defendants are to win, and possibly avoid, dispute. The party that is interested in precedent (in this case, the defendant software developers) will litigate until a favorable decision is met. This means that manufactures that are likely to be involved in accident disputes will make preventative efforts to improve the safety of their products to avoid liability costs in court cases and more easily defend themselves in case of a dispute \cite{FAKE}. 

\section{Summary}
Software engineers who work on safety critical software constantly make decisions on design and implementation details of the products they work on. These decisions will ultimately affect the safety of their product. The law regulates these engineers by holding them accountable for their implementation to standard that is the safest and most feasible at the time the product was built.

Accountability is enforced through products liability law. Namely, engineers can be found negligent for the decisions they made and alternatives they failed to consider. The requirements for a negligence case are unambiguous and safety-critical software engineers clearly fall under their jurisdiction. Since negligence is a determination of behavior and conduct, it can be best demonstrated by examining their processes.

\chapter{Software Processes}\label{software_process}
\begin{quote}
``\textit{This work must be conducted with attention to detail and the highest standard of professional care.}''
\flushright{\textsc{-Code of Business Conduct, St. Jude Medical} \cite{SJMCode}}
\end{quote}

The capabilities of software have, no doubt, changed dramatically since the introduction of computers decades ago. Society's increasing reliance on computers and software creates pressure to adapt. Software evolves because individuals and organizations are integrating computers into their activities \cite{Lehman98}.

In order to build quality software systems, many organizations follow a formal approach to the software development process including formal methods, best practices, and adoption of standards. Returning to the \textit{Killer Robot} case study from last chapter, it can be argued that the diligent adoption of some formal method could have reduced the likelihood of an accident. The following sections outline the basic models of the software process and how their application could have helped in the Case of the Killer Robot.

\section{Basic Models of the Software Process}  
Diligent adoption of modeled software processes, be it intentional or incidental, can in many ways fulfill the ``due care'' requirements set forth by judicial authorities. The waterfall and spiral models shown below model the software development process for individual projects. Both are acceptable models to use on a software development project, but the spiral model seems to be more accepted because it is a current, generalized version of many of the previous models and accommodates for for different types of methodologies depending on its application.

\subsection{Waterfall Model}
\begin{figure}[t]
\begin{center}
\includegraphics[scale=0.7]{figures/waterfall.pdf}
\end{center}
\caption{Waterfall Model of the Software Process}
\label{fig:waterfall}
\end{figure}
The original treatment of the waterfall model appears in \cite{Royce1970} and describes a specification-driven approach to software development. Figure \ref{fig:waterfall} shows different phases that flow steadily downwards, like a waterfall. The model stresses a sequential occurrence of events in software development, but also includes an iterative treatment to account for the evolving software development process.

This model shows the widely-accepted phases of the software development process, but the specific details within each phase are not set-in-stone. The model defines activities that should go on during requirements, analysis, implementation, etc. But societal demands may require other considerations to be made during these phases.

\subsection{Spiral Model}\label{spiral}
\begin{figure}[t]
\begin{center}
\includegraphics{figures/spiral.pdf}
\end{center}
\caption{Spiral Model of the Software Process}
\label{fig:spiral}
\end{figure}

The spiral model, as described in \cite{Boehm1986}, builds on refinements made to the waterfall model. Boehm explains that the software process as an iteration of four phases of activity -- shown as quadrants – which can be retrofitted to particularize to a variety of methods and approaches. As illustrated in Figure \ref{fig:spiral}, the radial dimension represents the cumulative costs incurred in accomplishing the steps to date while the angular dimension represents the progress made in completing each spiral.

Notice that each rotation around the spiral begins with objectives, consideration of alternatives, and the constraints on the system so (cost, schedule, interface, etc.). According to Boehm's model, software developers should take risks into consideration and these considerations should be documented.

\section{Reasonably Prudent Software Development}
While there are several methodologies to model the software development process beyond waterfall and spiral, one prudent attribute that they all should have in common is \textit{\textbf{iteration}}. With iteration, software engineers perform the activities they would follow to build the entire project during each iteration. There are different terms that define the activity during these iterations, but in general, software development occurs in three phases: design, implementation, and test. This section does not attempt to exhaustively describe the state-of-the-art of all software engineering activity, but intends to expose the key points of these three general activities and reveal how applying the respective state-of-the-art in these areas can prevent harm.

\textbf{Design}: Herbert Simon would classify design in general as the formulation actions that will ``change existing situations into preferred ones''. From software engineering standpoint, designers are concerned with how things ought to be in order to attain goals and function \cite{Simon96}. Activities can include gathering requirements, developing external functions and interfaces, designing internal component structures, generating test plans, and ensuring functions are complete and achievable.

Defects in design are difficult to prevent as there are no automated tools to detect them. By analyzing risk and borrowing the best practices from the state-of-the-art, software designers can reduce the number of defects that get written into the code. Using the killer robot case as an example, it can be argued that the design of the user interface of their Robbie CX30 did not comply with the state-of-the-art. Careful study of design principles and involvement of UI experts would have found this design defect so that it could be corrected in subsequent implementation iterations.

\textbf{Implement}: Implementation involves converting the specifications from the design into actual software code. Reasonably prudent software engineers use modern tools and distinct methodologies to implement software. Sometimes referred to as software construction or coding, engineers will implement code to create a static description of the processes defined in the prior phase, usually in the form of a programming language.

The state-of-the-art of software implementation is constantly evolving. Software compilers translate human-readable code written by programmers into machine bits or byte/object code. Syntax mistakes and simple error conditions can be detected by compilers and prevent software defects. Compilation typically happens soon or immediately after a programmer finishes a unit of programming work. But advanced integrated development environments often provide real-time compilation that happens during development so that these simple errors are detected as the programmer is writing code.  

As software has matured, certain programming practices have been universally recognized as the state-of-the art. For example, static code analyzers like FxCop or FindBugs are more sophisticated than a compiler and can detect certain violations of these best-practices. Analyzers can detect potential dynamic, or runtime errors, without actually executing the code. This is beneficial because reproducing every possible code path in tests is difficult, and arguably impossible, to achieve. Static code analysis typically happens after a complete unit of programming finishes and an analyzer can run on either the source or object code. 

Like design, there several implementation tools and methodologies that can be considered state-of-the-art depending on their application. In the killer robot scenario, one of the mistakes made by the developer on the Robbie CX30 project was a misinterpretation of a formula in the design that manifested itself by altering the movement of the robot's arm. Integrating software tools like static code analysis may have prevented this type of defect depending on the severity of the defect, but adopting implementation methodologies like code reviews or pair programming \cite{Williams00} would have certainly reduced the risk of this type of defect making into the release implementation.

\textbf{Test}: Testing is the validation of the implementation against the programs design. This can be done through a variety of ways including, but not limited to, unit and system testing, black box testing, static code analysis, and automated testing. Testers seek to discover defects so that engineers can fix them before the code is released to the public.

When software is complete enough to be executed, a series of unit and system level tests run to validate the code against its expected behavior. In  addition to automated test cases, test engineers run black-box style tests to mimic real-world usage.

In an article from the case of the killer robot, investigators report that test cases were not authentic and did not represent the expected usage of the product. Evidence of a test plan and automation of many of the usage scenarios would have made the project more defensible. Similar to mistakes in other areas of the software development lifecycle, engineers could have minimized risk by complying to the software testing state-of-the-art.

\section{Summary}

Models of these processes show that the the evolution of software is both a proactive, feed-forward system as well as a reactive, feedback system. The processes are proactive because software developers use the demands of their clients to write requirements for what they will implement. Society pushes them to innovate and create software that will be profitable. At the same time, the process is reactive because testing occurs to detect errors and inadequacies and are reported back to requirements and design planning for corrections. What is key to understand about the constantly evolving software industry is that different process models are more appropriate for each project and no matter which model is chosen it is always beneficial to iterate cycles of the process. Iteration provides more opportunities to find mistakes, consider risks, and update the implementations as requirements are sure to change.

The study of these models will help software engineers choose the best approach for their projects and understand the legal requirements that are already integrated in their processes. The law requires that if a reasonable alternative design is available it should be implemented. By using iteration in their process, software organizations are less likely to overlook these alternatives.

\chapter{Paving the Intersection}
While the common law works in a reactive manner, software engineers do not have to. In fact, software engineers have influence over the very laws that constrain their work. Just like implementation defects are tested against the design, design defects are tested against the state-of-the-art. But the state-of-the-art is not a court-created criterion. It is a standard created by software engineers themselves!

In a dispute, the state-of-the art is defined as the best set of tools, technologies, and processes that could have been used at the time of a product's construction. This benchmark is defined software engineering academics and industry. It is created by expert groups in standards and best practices. It is taught in universities and understood by professors and students alike. It is utilized in industry among all successful software engineering projects. In this way, software engineers are able to influence the legal standard they are held to.

\section{Scopes of Influence}  
In a legal context, different perspectives are used to scrutinize the liability of software. Each perspective has its own scope to which it can influence its encapsulated perspectives. The initial level is the software implementation perspective. To determine liability based on a manufacturing defect, the implementation is scrutinized against the engineers' design of the product. Thus, the implementation perspective is encapsulated by the design perspective.  

Beyond a simple manufacturing defect liability, software engineers can also be negligent if their design is unsafe. To determine negligence, the design itself is judged against a standard outside of the specification of the project. Courts normally refer to this outside standard as the ``State-of-the-Art. This perspective is used to determine if the behavior of software engineers, in the form of their design, was negligent. The state-of-the-art can influence a software products design, and by virtue its implementation, because its perspective has a wider scope than software design.  

\begin{figure}[t]
\begin{center}  
\includegraphics{figures/scopes.pdf}  
\end{center}  
\caption{Scopes of Influence}  
\label{fig:scopes}
\end{figure}

While software engineers are in fact held accountable by a legal system that, by itself, lacks the technical merit to pass judgment on such a specialized field, they can influence the very standard against which they are judged. Software engineering experts from both industry and academia, by the very nature of their work, define what constitutes the state-of-the-art. Thus, two more perspectives are introduced whose scopes encapsulate all others: Academia and Industry. Both perspectives have, qualitatively, equal influence over the software engineering state-of-the-art and its underlying perspectives so one cannot encapsulate the other. However, since both perspectives borrow expertise from one another, they can mutually influence each other.   Figure \ref{fig:scopes} illustrates the concept of these perspectives and their influence over each other.


\chapter{Conclusion}  
Software safety, for now, remains an impracticable desire. While the precautions and recommendations derived from this research can assist in improving the overall safety and quality of software products, they cannot be held to the same regard as professional standards. The software industry still needs time to mature and society must learn to recognize that software is engineering.  

\section{Drawbacks and Limitations}  
Building software with safety constraints affirmed to the same level as medicine, architecture, or even other fields of physical engineering, is unlikely to happen within the near future. Certain inequities of the industry and limitations of the medium prevent software engineers from ensuring the safety of software like other industries are able to. Just as the software profession is lacking in legal history, these legal shortcomings mutually hinder the effectiveness of software engineers.  

\subsection{Why We Can't Guarantee Software Safety}  
Society is accustomed to software solutions built faster and cheaper. Imposing constraints to improve safety will slow down the speed in which developers can implement solutions; a speed at which safety-critical clients already expect them to deliver at. In addition, adding longer and more thorough development patterns will add to the cost of the solution. But if the cost of a safer software solution is slower and more expensive to build, clients may not see any value of using software over traditionally engineered solutions.

Additionally, software development jobs are not all safety-critical. Unlike other professions, the vast majority of jobs available to computer science graduates are in enterprise and end-user software that is not safety-critical \cite{FAKE}. Since these areas do not need safety-regulation the way that all doctors, architects, and physical engineers do, the industry and regulating bodies are less likely to pay attention to software safety.

\subsection{Why We Shouldn't Guarantee Software Safety}  
Creating a strict standard will hinder technical progress. Software is still in a state where it is evolving quickly, and if a hasty standard is created, it will either halt technical progress at the point where the standard is, or will quickly become obsolete and unable to catch up to the progress that non-safety-critical software developers are working on.

A defined standard may reduce software quality. Again, since software progress is moving so quickly, software engineers could choose to only follow a standard which at the time is obsolete and insufficient for proper safety. Without the existence of an official, strict standard, the safety of an application is evaluated on a case-by-case basis. Engineers should take the necessary precautions beyond what is considered sufficient to guarantee safety because there is no minimum benchmark to meet.  

\section{Future Work}  

It would not be difficult to expand this research beyond the scope of software engineering. Standards and practices exist for other areas of engineering, as well as legal requirements. Much of what has been written can be generalized to these fields.

\appendix
\include{killerrobot}
\include{upchurch}
\include{roberts}

\bibliographystyle{acm}  
\addcontentsline{toc}{chapter}{Bibliography}  
\bibliography{references}  

\end{document}  
